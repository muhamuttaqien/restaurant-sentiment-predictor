{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import xml.etree.ElementTree as et\n",
    "import nltk\n",
    "import numpy as np\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "from nltk import pos_tag\n",
    "from nltk import CRFTagger\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = et.parse(\"training_set_SentenceCleaned.xml\")\n",
    "\n",
    "root = tree.getroot()\n",
    "\n",
    "#[1,2,3,4] list\n",
    "\n",
    "for reviewElement in root:\n",
    "\n",
    "    #print(reviewElement.tag,reviewElement.attrib)\n",
    "    newSentencesEl = et.Element('sentences')\n",
    "    reviewElement.insert(1,newSentencesEl)\n",
    "    for subChild in reviewElement:\n",
    "        #print(subChild.tag,subChild.attrib)\n",
    "        if subChild.tag == 'cleansentence':\n",
    "           reviewTextContent = subChild.text.split('.')\n",
    "           attrNum = 1\n",
    "           for sentenceNumber in range(0,len(reviewTextContent)):\n",
    "               if len(reviewTextContent[sentenceNumber]) != 0: \n",
    "                   word_tokens = word_tokenize(reviewTextContent[sentenceNumber].strip())\n",
    "                   # POS Tagging with CRFTagger in Indonesian\n",
    "                   ct = CRFTagger()\n",
    "                   ct.set_model_file('all_indo_man_tag_corpus_model.crf.tagger')\n",
    "                   tag_indo = ct.tag_sents(word_tokens)\n",
    "                   print(tag_indo)\n",
    "                   #POS Tagging in English\n",
    "                   tag_eng = nltk.pos_tag(word_tokens)\n",
    "                   print(tag_eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Sengaja', 'NNP'), ('macet2an', 'CD'), ('kesini', 'NN'), ('cuman', 'NN'), ('buat', 'JJ'), ('nyobain', 'IN'), ('nasi', 'NN'), ('goreng', 'NN'), ('cakalang', 'NN'), ('orang2', 'CD'), ('bilang', 'NN'), ('enak', 'NN'), ('Dan', 'CC'), ('emang', 'NN'), ('beneran', 'NN'), ('enak', 'NN'), ('sih', 'NN'), ('nasi', 'NN'), ('gorengnya', 'RB'), ('wkkw', 'VB'), ('suasana', 'NN'), ('nya', 'NN'), ('enak', 'NN'), ('buat', 'JJ'), ('makan', 'VB'), ('ramai2', 'CD'), ('gitu', 'NN'), ('Suka', 'NN'), ('sama', 'JJ'), ('bebek', 'NN'), ('karna', 'NN'), ('dulu', 'NN'), ('ajak', 'NN'), ('tmn', 'NN'), ('makan', 'VB'), ('sini', 'PR'), (',', 'Z'), ('ehh', 'VB'), ('malah', 'NN'), ('jd', 'NN'), ('ketagihan', 'NN'), ('sama', 'JJ'), ('dagingnya', 'RB'), ('yg', 'VB'), ('empuk', 'NN'), ('sambel', 'NN'), ('mentah', 'NN'), ('nya', 'NN'), ('yg', 'FW'), ('dasyatttt', 'FW'), ('Dulu', 'NNP'), ('tempatnya', 'RB'), ('tenda', 'VB'), (',', 'Z'), ('sekarang', 'NN'), ('udh', 'NN'), ('kiosnya', 'RB'), (',', 'Z'), ('kursinya', 'RB'), ('lumayan', 'VB'), ('banyak', 'CD'), ('toilet', 'NN'), ('nya', 'PRP')]\n"
     ]
    }
   ],
   "source": [
    "review = \"Sengaja macet2an kesini cuman buat nyobain nasi goreng cakalang orang2 bilang enak Dan emang beneran enak sih nasi gorengnya wkkw suasana nya enak buat makan ramai2 gitu Suka sama bebek karna dulu ajak tmn makan sini , ehh malah jd ketagihan sama dagingnya yg empuk sambel mentah nya yg dasyatttt Dulu tempatnya tenda , sekarang udh kiosnya , kursinya lumayan banyak toilet nya\"\n",
    "review = word_tokenize(review)\n",
    "review_arr = []\n",
    "review_arr.append(review)\n",
    "ct = CRFTagger()\n",
    "ct.set_model_file('all_indo_man_tag_corpus_model.crf.tagger')\n",
    "tag_indo = ct.tag_sents(review_arr)\n",
    "tag_indo = tag_indo[0]\n",
    "print(tag_indo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('I', 'PRP'), ('love', 'VBP'), ('concept', 'NN'), ('I', 'PRP'), ('feel', 'VBP'), ('like', 'IN'), ('swiss', 'JJ'), ('traditional', 'JJ'), ('market', 'NN'), ('The', 'DT'), ('place', 'NN'), ('amazing', 'VBG'), ('The', 'DT'), ('food', 'NN'), ('awesome', 'NN'), ('But', 'CC'), (',', ','), ('opinion', 'NN'), (',', ','), ('need', 'VBP'), ('make', 'VBP'), ('change/rotation', 'NN'), ('menu', 'NNS'), ('even', 'RB'), ('new', 'JJ'), ('menu', 'NN'), ('I', 'PRP'), ('choose', 'VBP'), ('place', 'NN'), ('lunch', 'NN'), ('frequently', 'RB'), ('Sometimes', 'RB'), ('I', 'PRP'), ('feel', 'VBP'), ('bored', 'JJ'), ('menu', 'NN'), ('Overall', 'NNP'), (',', ','), ('thanks', 'NNS'), ('Marche', 'NNP'), ('delicious', 'JJ'), ('food', 'NN'), (',', ','), ('also', 'RB'), ('nice', 'JJ'), ('place', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "review = \"I love concept I feel like swiss traditional market The place amazing The food awesome But , opinion , need make change/rotation menu even new menu I choose place lunch frequently Sometimes I feel bored menu Overall , thanks Marche delicious food , also nice place\"\n",
    "review = word_tokenize(review)\n",
    "tag_eng = nltk.pos_tag(review)\n",
    "print(tag_eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering: POS Tagging\n",
    "# POS Tagging in Indonesian\n",
    "\n",
    "import numpy as np\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "from nltk import pos_tag\n",
    "from nltk import CRFTagger\n",
    "\n",
    "pos_tagged_review = []\n",
    "\n",
    "ct = CRFTagger()\n",
    "ct.set_model_file('all_indo_man_tag_corpus_model.crf.tagger')\n",
    "\n",
    "for id, review in enumerate(id_processed_reviews):\n",
    "    review = \"\".join(review)\n",
    "    review = ''.join(''.join(s)[:2] for _, s in itertools.groupby(review))\n",
    "    tokens = word_tokenize(review)\n",
    "    tokens_arr = []\n",
    "    tokens_arr.append(review)\n",
    "    \n",
    "    joint_token = []\n",
    "    for token in tokens_arr:\n",
    "        tag_indo = ct.tag_sents(review_arr)\n",
    "        tag_indo = tag_indo[0]\n",
    "        token = tag_indo\n",
    "        joint_token.append(token)\n",
    "    \n",
    "    joint_token_str = \" \".join(joint_token)   \n",
    "    pos_tagged_review.append(joint_token_str)\n",
    "\n",
    "display_review(pos_tagged_review)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
